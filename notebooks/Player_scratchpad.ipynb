{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from poke_env.player_configuration import PlayerConfiguration\n",
    "from poke_env.player.random_player import RandomPlayer\n",
    "from poke_env.player.baselines import SimpleHeuristicsPlayer\n",
    "from poke_env.server_configuration import ShowdownServerConfiguration\n",
    "from poke_env.player.utils import cross_evaluate\n",
    "\n",
    "from tabulate import tabulate\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "player = SimpleHeuristicsPlayer(\n",
    "    player_configuration=PlayerConfiguration(\"JoeNextLine\", \"underground\"),\n",
    "    server_configuration=ShowdownServerConfiguration,\n",
    ")\n",
    "\n",
    "await player.send_challenges(\"meatout\", n_challenges=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nacha\\Miniconda3\\envs\\pk_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\nacha\\Miniconda3\\envs\\pk_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\nacha\\Miniconda3\\envs\\pk_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\nacha\\Miniconda3\\envs\\pk_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\nacha\\Miniconda3\\envs\\pk_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\nacha\\Miniconda3\\envs\\pk_env\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\nacha\\Miniconda3\\envs\\pk_env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\nacha\\Miniconda3\\envs\\pk_env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\nacha\\Miniconda3\\envs\\pk_env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\nacha\\Miniconda3\\envs\\pk_env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\nacha\\Miniconda3\\envs\\pk_env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\nacha\\Miniconda3\\envs\\pk_env\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from dotmap import DotMap \n",
    "\n",
    "\n",
    "from pokebot.bots.state_engine import SimpleStateEngine\n",
    "from pokebot.bots.bot import BotPlayer\n",
    "from pokebot.models.dqn import Model\n",
    "from pokebot.trainers.trainer import SimpleDQNTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DotMap(attr='eps', value_max=1.0, value_min=0.5, value_test=0, nb_steps=10000)\n"
     ]
    }
   ],
   "source": [
    "hparams = DotMap(json.load(open('./hparams.json', 'r')))\n",
    "p_dict = hparams.policy\n",
    "a_dict = hparams.agent\n",
    "\n",
    "print((p_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_configuration=PlayerConfiguration(\"JoeNextLine\", \"underground\"),\n",
    "server_configuration=ShowdownServerConfiguration,\n",
    "\n",
    "player = BotPlayer(\n",
    "    player_configuration=PlayerConfiguration(\"test1\",None),\n",
    "#     log_level=10,\n",
    "    state_engine=SimpleStateEngine(10)\n",
    "    )\n",
    "\n",
    "model = Model(player)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = SimpleDQNTrainer(player, model, p_dict, a_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 100000 steps ...\n",
      "Interval 1 (0 steps performed)\n",
      "10000/10000 [==============================] - 100s 10ms/step - reward: 0.3983\n",
      "210 episodes - episode_reward: 18.981 [-44.130, 47.322] - loss: 0.011 - mae: 0.353 - mean_q: 0.572 - mean_eps: 0.725\n",
      "\n",
      "Interval 2 (10000 steps performed)\n",
      "10000/10000 [==============================] - 105s 11ms/step - reward: 0.6677\n",
      "246 episodes - episode_reward: 27.129 [-41.040, 47.801] - loss: 0.014 - mae: 0.322 - mean_q: 0.509 - mean_eps: 0.500\n",
      "\n",
      "Interval 3 (20000 steps performed)\n",
      "10000/10000 [==============================] - 105s 11ms/step - reward: 0.7298\n",
      "259 episodes - episode_reward: 28.147 [-45.200, 47.165] - loss: 0.014 - mae: 0.323 - mean_q: 0.507 - mean_eps: 0.500\n",
      "\n",
      "Interval 4 (30000 steps performed)\n",
      "10000/10000 [==============================] - 105s 11ms/step - reward: 0.6626\n",
      "249 episodes - episode_reward: 26.631 [-41.010, 47.143] - loss: 0.014 - mae: 0.337 - mean_q: 0.530 - mean_eps: 0.500\n",
      "\n",
      "Interval 5 (40000 steps performed)\n",
      "10000/10000 [==============================] - 105s 10ms/step - reward: 0.7440\n",
      "263 episodes - episode_reward: 28.275 [-40.930, 47.901] - loss: 0.014 - mae: 0.342 - mean_q: 0.538 - mean_eps: 0.500\n",
      "\n",
      "Interval 6 (50000 steps performed)\n",
      "10000/10000 [==============================] - 105s 11ms/step - reward: 0.8063\n",
      "262 episodes - episode_reward: 30.805 [-40.530, 47.515] - loss: 0.015 - mae: 0.369 - mean_q: 0.590 - mean_eps: 0.500\n",
      "\n",
      "Interval 7 (60000 steps performed)\n",
      "10000/10000 [==============================] - 108s 11ms/step - reward: 0.7383\n",
      "255 episodes - episode_reward: 28.949 [-39.550, 47.050] - loss: 0.014 - mae: 0.342 - mean_q: 0.549 - mean_eps: 0.500\n",
      "\n",
      "Interval 8 (70000 steps performed)\n",
      "10000/10000 [==============================] - 104s 10ms/step - reward: 0.6715\n",
      "250 episodes - episode_reward: 26.857 [-39.640, 47.894] - loss: 0.014 - mae: 0.338 - mean_q: 0.541 - mean_eps: 0.500\n",
      "\n",
      "Interval 9 (80000 steps performed)\n",
      "10000/10000 [==============================] - 104s 10ms/step - reward: 0.7121\n",
      "260 episodes - episode_reward: 27.357 [-37.180, 47.509] - loss: 0.014 - mae: 0.336 - mean_q: 0.530 - mean_eps: 0.500\n",
      "\n",
      "Interval 10 (90000 steps performed)\n",
      "10000/10000 [==============================] - 106s 11ms/step - reward: 0.7649\n",
      "done, took 1046.740 seconds\n"
     ]
    }
   ],
   "source": [
    "await trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results against player: <poke_env.player.baselines.MaxBasePowerPlayer object at 0x00000234250CF2E8>\n",
      "DQN Evaluation: 69 victories out of 100 episodes\n",
      "Results against player: <poke_env.player.baselines.SimpleHeuristicsPlayer object at 0x00000234250B8748>\n",
      "DQN Evaluation: 15 victories out of 100 episodes\n"
     ]
    }
   ],
   "source": [
    "from poke_env.player.baselines import MaxBasePowerPlayer, SimpleHeuristicsPlayer\n",
    "\n",
    "opponents = [MaxBasePowerPlayer(battle_format=\"gen8randombattle\"),\n",
    "             SimpleHeuristicsPlayer(battle_format=\"gen8randombattle\")]\n",
    "\n",
    "await trainer.evaluate(opponents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save current player\n",
    "\n",
    "trainer.agent.save_weights(\"../data/agents/simple_dqn.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load agent\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pkmn)",
   "language": "python",
   "name": "pk_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
